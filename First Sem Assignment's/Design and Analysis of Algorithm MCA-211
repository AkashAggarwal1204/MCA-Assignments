Question 1. a) What are the desirable characteristics of an algorithm? Find the GCD of p = 144 and q = 55 using Euclid’s algorithm.

Answer. 1)Input specified : 
The input is the data to be transformed during the computation to produce the output.An algorithm should have 0 or 
more well-defined inputs.Input precision requires that you know what kind of data, how much and what form the data should be

2)Output specified : 
The output is the data resulting from the computation (your intended result). An algorithm should have 1 or more well-defined
outputs, and should match the desired output.Output precision also requires that you know what kind of data, how much and what form the output should 
be (or even if there will be any output at all!).

3)Definiteness : 
Algorithms must specify every step and the order the steps must be taken in the process.Definiteness means specifying the sequence of 
operations for turning input into output. Algorithm should be clear and unambiguous.Details of each step must be also be spelled out (including how to handle errors).
It should contain everything quantitative and not qualitative.

4)Effectiveness : 
For an algorithm to be effective, it means that all those steps that are required to get to output must be feasible with the available 
resources.It should not contain any unnecessary and redundant steps which could make an algorithm ineffective.

5)Finiteness :
The algorithm must stop, eventually.Stopping may mean that you get the expected output OR you get a response that no solution is possible. Algorithms must terminate
after a finite number of steps.An algorithm should not be infinite and always terminate after definite number of steps. 

There is no point in developing an algorithm which is infinite as it will be useless for us.

6)Independent :
An algorithm should have step-by-step directions, which should be independent of any programming code.It should be such that it could be run on any of the programming languages.
Thus,these are the characteristics that an algorithm should have for its fruitfulness.

--> Find the GCD of p = 144 and q = 55 using Euclid’s algorithm.

GCD of 144 and 55


144 > 55

a = bq + r (0≤r<b)

114  = 55 x 2 + 34
55 = 34 x 1 + 21
34 = 21 x 1 + 13
21 = 13 x 1 + 8
13 = 8 x 1 + 5 
8 = 5 x 1 + 3
5 = 3 x 1 + 2
3 = 2 x 1 + 1
2 = 1 x 1 + 1
1 = 1 x 1 + 0

Here, r = 0
Therefore, Divisor is the GCD
Hence, 1 is the greatest common divisor(GCD) of 144 & 55


--> Find the GCD of p = 144 and q = 55 using Java.

--> First approach

public class GCD {
	
	public static void main(String[] args) {
		int a = 144;
		int b = 55;
		int r;
		do {
			r = a%b;
			a = b;
			b = r;
		} while (r != 0);
		System.out.println(a);
		
		
	}

}

Output = 1


--> Second approach

public class GCD {
	
	 static int gcd(int a, int b)
	    {
	        if (a == 0)
	          return b;
	        if (b == 0)
	          return a;
	      
	        if (a == b)
	            return a;
	        if (a > b)
	            return gcd(a-b, b);
	        return gcd(a, b-a);
	    }
	
	public static void main(String[] args) {
		int p = 114;
		int q = 55;
		System.out.println(gcd(p,q));
	}
	

}

Output = 1



Question 1. b) Differentiate between Greedy Technique and Dynamic Programming approach of problem solving. Name few problems which are solved using these techniques

Answer.
Greedy approach :
A Greedy algorithm is an algorithmic paradigm that builds up a solution piece by piece, always choosing the next piece that offers the most obvious and 
immediate benefit. So the problems where choosing locally optimal also leads to a global solution are best fit for Greedy. For example, consider the Fractional 
Knapsack Problem. The local optimal strategy is to choose the item that has maximum value vs weight ratio. This strategy also leads to global optimal solution
because we allowed taking fractions of an item. 

 Dynamic programming :
 Dynamic programming is mainly an optimization over plain recursion. Wherever we see a recursive solution that has repeated calls for the same inputs, we can optimize
 it using Dynamic Programming. The idea is to simply store the results of subproblems so that we do not have to re-compute them when needed later. This simple
 optimization reduces time complexities from exponential to polynomial. For example, if we write a simple recursive solution for Fibonacci Numbers, we get exponential
 time complexity and if we optimize it by storing solutions of subproblems, time complexity reduces to linear. 
 
 
 Feature	                                                            Greedy method                                         	                                                                                          Dynamic programming
Feasibility	  In a greedy Algorithm, we make whatever choice seems best at the moment in the hope that it will lead to global optimal solution.            In Dynamic Programming we make decision at each step considering current problem and solution to previously solved sub problem to calculate optimal solution .
Optimality	  In Greedy Method, sometimes there is no such guarantee of getting Optimal Solution.	                                                       It is guaranteed that Dynamic Programming will generate an optimal solution as it generally considers all possible cases and then choose the best.
Recursion	  A greedy method follows the problem solving heuristic of making the locally optimal choice at each stage.                                    A Dynamic programming is an algorithmic technique which is usually based on a recurrent formula that uses some previously calculated states.
Memoization	  It is more efficient in terms of memory as it never look back or revise previous choices	                                               It requires dp table for memoization and it increases it’s memory complexity.
Time complexity	  Greedy methods are generally faster. For example, Dijkstra’s shortest path algorithm takes O(ELogV + VLogV) time.	                       Dynamic Programming is generally slower. For example, Bellman Ford algorithm takes O(VE) time.
Fashion	          The greedy method computes its solution by making its choices in a serial forward fashion, never looking back or revising previous choices.  Dynamic programming computes its solution bottom up or top down by synthesizing them from smaller optimal sub solutions.






Question 2. a) Prove that, for all positive integers n, 1 + 2 + 4 + ⋯ + 2! = 2!"# − 1

Answer.
Consider the given statement
P(n):1+2+4+...2ⁿ=2ⁿ⁺¹−1, for natural numbers n.
Step I We observe that P(0) is true.
P(2):1+2+4=8−1
7=7, which is true.
Step II Now, assume that P(n) is true for n=k.
So, P(k) : 1+2+4+...2ᵏ=2ᵏ⁺¹−1 is true.
Step III Now, to prove P(k+1) is true.
P(k+1):1+2+4+...+2ᵏ+2ᵏ⁺¹
=2ᵏ⁺¹−1+2ᵏ⁺¹
=2⋅2ᵏ⁺¹−1
=2ᵏ⁺¹+1−1
So, P(k+1) is true, whenever P(k) is true.
Hence, P(n) is true.


Question 2. b) What are asymptotic notations? Explain the significance of Big- O, Omega and theta notations with suitable example.
Answer. Asymptotic notations are the mathematical notations used to describe the running time of an algorithm when the input tends towards 
a particular value ora limiting value.

For example: 
In bubble sort, when the input array is already sorted, the time taken by the algorithm is linear i.e. the best case.
But, when the input array is in reverse condition, the algorithm takes the maximum time (quadratic) to sort the elements i.e. the worst case.
When the input array is neither sorted nor in reverse order, then it takes average time. These durations are denoted using asymptotic notations.
There are mainly three asymptotic notations:

Big-O notation
Omega notation
Theta notation

Big-O Notation (O-notation)
Big-O notation represents the upper bound of the running time of an algorithm. Thus, it gives the worst-case complexity of an algorithm.

https://cdn.programiz.com/sites/tutorial2program/files/big0.png

O(g(n)) = { f(n): there exist positive constants c and n0
            such that 0 ≤ f(n) ≤ cg(n) for all n ≥ n0 }
The above expression can be described as a function f(n) belongs to the set O(g(n)) if there exists a positive constant c such that it lies between 0 and cg(n),
for sufficiently large n. For any value of n, the running time of an algorithm does not cross the time provided by O(g(n)).
Since it gives the worst-case running time of an algorithm, it is widely used to analyze an algorithm as we are always interested in the worst-case scenario.


Omega Notation (Ω-notation)
Omega notation represents the lower bound of the running time of an algorithm. Thus, it provides the best case complexity of an algorithm.

https://cdn.programiz.com/sites/tutorial2program/files/omega.png

Ω(g(n)) = { f(n): there exist positive constants c and n0 
            such that 0 ≤ cg(n) ≤ f(n) for all n ≥ n0 }
The above expression can be described as a function f(n) belongs to the set Ω(g(n)) if there exists a positive constant c such that it lies above cg(n), 
for sufficiently large n. For any value of n, the minimum time required by the algorithm is given by Omega Ω(g(n)).

Theta Notation (Θ-notation)
Theta notation encloses the function from above and below. Since it represents the upper and the lower bound of the running time of an algorithm,
it is used for analyzing the average-case complexity of an algorithm.

https://cdn.programiz.com/sites/tutorial2program/files/theta.png

For a function g(n), Θ(g(n)) is given by the relation:

Θ(g(n)) = { f(n): there exist positive constants c1, c2 and n0
            such that 0 ≤ c1g(n) ≤ f(n) ≤ c2g(n) for all n ≥ n0 }
The above expression can be described as a function f(n) belongs to the set Θ(g(n)) if there exist positive constants c1 and c2 such that it can be
sandwiched between c1g(n) and c2g(n), for sufficiently large n. If a function f(n) lies anywhere in between c1g(n) and c2g(n) for all n ≥ n0, then f(n) is 
said to be asymptotically tight bound.

Question 3. a) Evaluate p(x)= 3ˣ⁴+2ˣ³-5ˣ+7 at x=2 using Horne’s rule. Show step wise iterations.

Since the polynomial is of the 4th degree, then n = 4


K	   4	              3	                    1         	       0
Step	b4 = 3        	b3 = 2 + 2 * 3	     b1 = -5 + 2 * 8	b0 = 7 + 2 * 11
Result	   3	              8	                    11	               29


Question 3. b) Sort the given sequence of numbers using Bubble sort. Write all the steps involved. 13, 15, 2, 6, 14, 10, 8, 7, 3, 5, 19, 4.

Answer.
public class BubbleSorting {
	
	public static void main (String[] args)
	{
		int[] arr = {13, 15, 2, 6, 14, 10, 8, 7, 3, 5, 19, 4};
		int[] ar = sort(arr);
		for(int a:ar) {
			System.out.print(a+",");
		}
	}

	private static int[] sort(int[] arr) {
		int n = arr.length;
		for(int i=0;i<n-1;i++) {
			for(int j=0;j<n-i-1;j++) {
				if(arr[j] > arr[j+1]) {
					int temp = arr[j];
					arr[j] = arr[j+1];
					 arr[j+1] = temp; 
				}
			}
			for(int s:arr)
				System.out.print(s+",");
				System.out.println();
		}
		return arr;
	}
}


Output. After Bubble Sorting 2,3,4,5,6,7,8,10,13,14,15,19

Is's iterate from start to end for each number and iterate array[before] > array[after] then replace to each other

Steps: [13],2,6,14,10,8,7,3,5,15,4,19
2,6,[13],10,8,7,3,5,14,4,15,19
2,6,[10],8,7,3,5,[13],4,14,15,19
2,6,8,7,3,5,10,4,[13],[14],15,19
2,6,7,3,5,8,4,10,13,[14],[15],19
2,[6],3,5,7,4,8,10,13,14,[15],[19]
2,3,5,[6],4,7,8,10,13,14,15,19
2,3,5,4,[6],[7],8,10,13,14,15,19
2,3,4,5,6,[7],[8],10,13,14,15,19
2,3,4,5,6,7,[8],[10],13,14,15,19
2,3,4,5,6,7,8,[10],[13],14,15,19
2,3,4,5,6,7,8,10,[13],[14],15,19

Question 4. a) Find an optimal solution for the knapsack instance n=6 and M=13, (p1, p2,…, p6)=(8, 5, 13, 7, 6, 15) (w1, w2,…, w6)=(3, 2, 4, 6, 2, 5)

Answer. 
Given: n=6 and M=13, (p1, p2,…, p6)=(8, 5, 13, 7, 6, 15) (w1, w2,…, w6)=(3, 2, 4, 6, 2, 5)

To prove: Optimal solution that gives maximum profit.
Proof:
Step 1: (To find profit/ weight ratio)
p1/w1 = 8/3 = 2.67
p2/w2 = 5/2 = 2.5
p3/w3 = 13/4 = 3.25
p4/w4 = 7/6 = 1.167
p5/w5 = 6/2 = 3
p6/w6 = 15/5 = 3

Step 2: (Arrange this profit/weight ratio in non-increasing order as n values) Since the highest profit/weight ratio is 3.25. That is p3/w3, so 1st value is 3. 
Second highest profit/weight ratio is 3. That is p5/w5, so 2nd value is 5. Similarly, calculate such n values and arrange them in non-increasing order.

Order = (3, 5, 6, 1, 2, 4)

Step 3: (To find optimal solution using m = 13 & n = 6)

Consider x3 = 1, profit = 13
Then consider x1 = 1, profit = 8
So weight uptil now = 4 + 3 = 7

Now x6 = 1, profit = 15
So total profit = 21 + 15 = 36
And weight uptil now = 7 + 5 = 12

Now x5 = 1, profit = 6
So total profit = 36 + 6 = 42
And weight uptil now = 12 + 2 = 14

Now x4 = 1, profit = 7
So total profit = 42 + 7 = 49
And weight uptil now = 14 + 6 = 20

Since m = 13 so we require only 2 units more. Therefore x2 = 2/3
So total profit = 49 + 8 x 2/3 = 49 + 3.33 = 52.3
And weight uptil now = 20 + 3 x 2/3 = 22
Thus, the optimal solution that gives maximum profit is,
(1, 2/3, 1, 0, 1, 1, 1)


Question 4. b) Write the Huffman code for the following set of frequencies of given symbols. A:1, B:1, K:2, D:3, F:5, G:8 , H:13, E:21.

Answer. Huffman coding is a lossless data compression algorithm. The idea is to assign variable-length codes to input characters, lengths of the assigned codes are based on the frequencies of corresponding characters. The most frequent character gets the smallest code and the least frequent character gets the largest code.
The variable-length codes assigned to input characters are Prefix Codes, means the codes (bit sequences) are assigned in such a way that the code assigned to one character is not the prefix of code assigned to any other character. This is how Huffman Coding makes sure that there is no ambiguity when decoding the generated bitstream. 
Let us understand prefix codes with a counter example. Let there be four characters a, b, c and d, and their corresponding variable length codes be 00, 01, 0 and 1. This coding leads to ambiguity because code assigned to c is the prefix of codes assigned to a and b. If the compressed bit stream is 0001, the de-compressed output may be “cccd” or “ccb” or “acd” or “ab”.
See this for applications of Huffman Coding. 
There are mainly two major parts in Huffman Coding

Build a Huffman Tree from input characters.
Traverse the Huffman Tree and assign codes to characters.

1. Create a leaf node for each unique character and build a min heap of all leaf nodes (Min Heap is used as a priority queue. The value of frequency field is used to compare two nodes in min heap. Initially, the least frequent character is at root)
2. Extract two nodes with the minimum frequency from the min heap.
 
3. Create a new internal node with a frequency equal to the sum of the two nodes frequencies. Make the first extracted node as its left child and the other extracted node as its right child. Add this node to the min heap.
4. Repeat steps#2 and #3 until the heap contains only one node. The remaining node is the root node and the tree is complete.
Let us understand the algorithm with an example:


character   Frequency
A             1
B	      1
K	      2
D	      3	
F             5
G             8
H             13
E             21

Step 1. Build a min heap that contains 6 nodes where each node represents root of a tree with single node.
Step 2 Extract two minimum frequency nodes from min heap. Add a new internal node with frequency 1 + 1 = 2. 

        2
       /\
      /  \
     /    \
    /      \
   /        \
  A:1       B:1   

Now min heap contains 7 nodes where 6 nodes are roots of trees with single element each, and one heap node is root of tree with 3 elements

character   Frequency
Internal Node  2
K	      2
D	      3	
F             5
G             8
H             13
E             21

Step 3: Extract two minimum frequency nodes from heap. Add a new internal node with frequency 12 + 13 = 25






